{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import json\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# GPU varsa kullan, yoksa CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Kullanƒ±lan cihaz:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2cKYkx2YxJB"
      },
      "source": [
        "Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YQYVn4A49_s9"
      },
      "outputs": [],
      "source": [
        "def load_vocab_from_json(json_file_path):\n",
        "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
        "        tokenizer_data = json.load(f)\n",
        "\n",
        "    vocab = tokenizer_data['model']['vocab']\n",
        "    return vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DtpLQ2m_Y1OC"
      },
      "outputs": [],
      "source": [
        "vocab = load_vocab_from_json(\"/content/my_bpe_tokenizer_dia.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSMfPMYw-CGI",
        "outputId": "0a24928c-cc5b-4f9e-a3f7-8dd9428bbe23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'<unk>': 0,\n",
              " '!': 1,\n",
              " '\"': 2,\n",
              " '$': 3,\n",
              " '%': 4,\n",
              " '&': 5,\n",
              " \"'\": 6,\n",
              " '(': 7,\n",
              " ')': 8,\n",
              " ',': 9,\n",
              " '-': 10,\n",
              " '.': 11,\n",
              " '/': 12,\n",
              " '0': 13,\n",
              " '1': 14,\n",
              " '2': 15,\n",
              " '3': 16,\n",
              " '4': 17,\n",
              " '5': 18,\n",
              " '6': 19,\n",
              " '7': 20,\n",
              " '8': 21,\n",
              " '9': 22,\n",
              " ':': 23,\n",
              " ';': 24,\n",
              " '=': 25,\n",
              " '?': 26,\n",
              " 'A': 27,\n",
              " 'B': 28,\n",
              " 'C': 29,\n",
              " 'D': 30,\n",
              " 'E': 31,\n",
              " 'F': 32,\n",
              " 'G': 33,\n",
              " 'H': 34,\n",
              " 'I': 35,\n",
              " 'J': 36,\n",
              " 'K': 37,\n",
              " 'L': 38,\n",
              " 'M': 39,\n",
              " 'N': 40,\n",
              " 'O': 41,\n",
              " 'P': 42,\n",
              " 'Q': 43,\n",
              " 'R': 44,\n",
              " 'S': 45,\n",
              " 'T': 46,\n",
              " 'U': 47,\n",
              " 'V': 48,\n",
              " 'W': 49,\n",
              " 'X': 50,\n",
              " 'Y': 51,\n",
              " 'Z': 52,\n",
              " 'a': 53,\n",
              " 'b': 54,\n",
              " 'c': 55,\n",
              " 'd': 56,\n",
              " 'e': 57,\n",
              " 'f': 58,\n",
              " 'g': 59,\n",
              " 'h': 60,\n",
              " 'i': 61,\n",
              " 'j': 62,\n",
              " 'k': 63,\n",
              " 'l': 64,\n",
              " 'm': 65,\n",
              " 'n': 66,\n",
              " 'o': 67,\n",
              " 'p': 68,\n",
              " 'q': 69,\n",
              " 'r': 70,\n",
              " 's': 71,\n",
              " 't': 72,\n",
              " 'u': 73,\n",
              " 'v': 74,\n",
              " 'w': 75,\n",
              " 'x': 76,\n",
              " 'y': 77,\n",
              " 'z': 78,\n",
              " '~': 79,\n",
              " '¬£': 80,\n",
              " '¬•': 81,\n",
              " '‚Äî': 82,\n",
              " '‚Äò': 83,\n",
              " '‚Ä≤': 84,\n",
              " '„ÄÇ': 85,\n",
              " 'er': 86,\n",
              " 'on': 87,\n",
              " 'ers': 88,\n",
              " 'erson': 89,\n",
              " 'Person': 90,\n",
              " 'th': 91,\n",
              " 'ou': 92,\n",
              " 'in': 93,\n",
              " 'an': 94,\n",
              " 'you': 95,\n",
              " 're': 96,\n",
              " 'at': 97,\n",
              " 'the': 98,\n",
              " 'to': 99,\n",
              " 'll': 100,\n",
              " 'it': 101,\n",
              " 'is': 102,\n",
              " 'me': 103,\n",
              " 'or': 104,\n",
              " 'es': 105,\n",
              " 'ing': 106,\n",
              " 've': 107,\n",
              " 'se': 108,\n",
              " 'le': 109,\n",
              " 'st': 110,\n",
              " 'ke': 111,\n",
              " 'ha': 112,\n",
              " 'ow': 113,\n",
              " 'ar': 114,\n",
              " 'he': 115,\n",
              " 'ere': 116,\n",
              " 'oo': 117,\n",
              " 'and': 118,\n",
              " 'hat': 119,\n",
              " 'of': 120,\n",
              " 'li': 121,\n",
              " 'ay': 122,\n",
              " 'for': 123,\n",
              " 'ch': 124,\n",
              " 'en': 125,\n",
              " 'et': 126,\n",
              " 'have': 127,\n",
              " 'ld': 128,\n",
              " 'be': 129,\n",
              " 'do': 130,\n",
              " 'gh': 131,\n",
              " 'al': 132,\n",
              " 'so': 133,\n",
              " 'ut': 134,\n",
              " 'are': 135,\n",
              " 'ri': 136,\n",
              " 'wi': 137,\n",
              " 'ce': 138,\n",
              " 'we': 139,\n",
              " 'all': 140,\n",
              " 'ould': 141,\n",
              " 'as': 142,\n",
              " 'ot': 143,\n",
              " 'one': 144,\n",
              " 'It': 145,\n",
              " 'ta': 146,\n",
              " 'ght': 147,\n",
              " 'like': 148,\n",
              " 'ed': 149,\n",
              " 'co': 150,\n",
              " 'can': 151,\n",
              " 'ver': 152,\n",
              " 'ir': 153,\n",
              " 'out': 154,\n",
              " 'ad': 155,\n",
              " 'that': 156,\n",
              " 'nd': 157,\n",
              " 'ne': 158,\n",
              " 'Yes': 159,\n",
              " 'What': 160,\n",
              " 'Th': 161,\n",
              " 'ple': 162,\n",
              " 'your': 163,\n",
              " 'ti': 164,\n",
              " 'this': 165,\n",
              " 'ab': 166,\n",
              " 'ro': 167,\n",
              " 'We': 168,\n",
              " 'id': 169,\n",
              " 'sh': 170,\n",
              " 'ood': 171,\n",
              " 'ase': 172,\n",
              " 'ck': 173,\n",
              " 'You': 174,\n",
              " 'ant': 175,\n",
              " 'ry': 176,\n",
              " 'go': 177,\n",
              " 'some': 178,\n",
              " 'The': 179,\n",
              " 'How': 180,\n",
              " 'ink': 181,\n",
              " 'now': 182,\n",
              " 'ter': 183,\n",
              " 'am': 184,\n",
              " 'su': 185,\n",
              " 'ly': 186,\n",
              " 'mu': 187,\n",
              " 'here': 188,\n",
              " 'mo': 189,\n",
              " 'my': 190,\n",
              " 'get': 191,\n",
              " 'with': 192,\n",
              " 'bu': 193,\n",
              " 'ra': 194,\n",
              " 'ook': 195,\n",
              " 'any': 196,\n",
              " 'thing': 197,\n",
              " 'about': 198,\n",
              " 'nt': 199,\n",
              " 'please': 200,\n",
              " 'ank': 201,\n",
              " 'there': 202,\n",
              " 'will': 203,\n",
              " 'want': 204,\n",
              " 'No': 205,\n",
              " 'our': 206,\n",
              " 'very': 207,\n",
              " 'think': 208,\n",
              " 'pe': 209,\n",
              " 'Do': 210,\n",
              " 'lo': 211,\n",
              " 'ge': 212,\n",
              " 'right': 213,\n",
              " 'if': 214,\n",
              " 'ally': 215,\n",
              " 'don': 216,\n",
              " 'take': 217,\n",
              " 'hi': 218,\n",
              " 'That': 219,\n",
              " 'not': 220,\n",
              " 'much': 221,\n",
              " 'ur': 222,\n",
              " 'ind': 223,\n",
              " 'ust': 224,\n",
              " 'si': 225,\n",
              " 'de': 226,\n",
              " 'day': 227,\n",
              " 'ea': 228,\n",
              " 'ure': 229,\n",
              " 'good': 230,\n",
              " 'but': 231,\n",
              " 'Thank': 232,\n",
              " 'ma': 233,\n",
              " 'would': 234,\n",
              " 'know': 235,\n",
              " 'fe': 236,\n",
              " 'see': 237,\n",
              " 'look': 238,\n",
              " 'ble': 239,\n",
              " 'ther': 240,\n",
              " 'ex': 241,\n",
              " 'OK': 242,\n",
              " 'Oh': 243,\n",
              " 'ent': 244,\n",
              " 'la': 245,\n",
              " 'time': 246,\n",
              " 'ine': 247,\n",
              " 'ic': 248,\n",
              " 'Can': 249,\n",
              " 'ight': 250,\n",
              " 'ap': 251,\n",
              " 'what': 252,\n",
              " 'up': 253,\n",
              " 'use': 254,\n",
              " 'way': 255,\n",
              " 'qu': 256,\n",
              " 'Well': 257,\n",
              " 'just': 258,\n",
              " 'ul': 259,\n",
              " 'ice': 260,\n",
              " 'sa': 261,\n",
              " 'too': 262,\n",
              " 'ion': 263,\n",
              " 'ho': 264,\n",
              " 'est': 265,\n",
              " 'il': 266,\n",
              " 'el': 267,\n",
              " 'ong': 268,\n",
              " 'pro': 269,\n",
              " 'un': 270,\n",
              " 'But': 271,\n",
              " 'ba': 272,\n",
              " 'need': 273,\n",
              " 'Is': 274,\n",
              " 'hel': 275,\n",
              " 'ound': 276,\n",
              " 'orry': 277,\n",
              " 'Here': 278,\n",
              " 'ct': 279,\n",
              " 'com': 280,\n",
              " 'ive': 281,\n",
              " 'art': 282,\n",
              " 'was': 283,\n",
              " 'come': 284,\n",
              " 'ill': 285,\n",
              " 'af': 286,\n",
              " 'sir': 287,\n",
              " 'po': 288,\n",
              " 'ment': 289,\n",
              " 'they': 290,\n",
              " 'ite': 291,\n",
              " 'buy': 292,\n",
              " 'sto': 293,\n",
              " 'ci': 294,\n",
              " 'help': 295,\n",
              " 'che': 296,\n",
              " 'car': 297,\n",
              " 'ell': 298,\n",
              " 'um': 299,\n",
              " 'Let': 300,\n",
              " 'res': 301,\n",
              " 'should': 302,\n",
              " 'no': 303,\n",
              " 'pen': 304,\n",
              " 'roo': 305,\n",
              " 'Sure': 306,\n",
              " 'more': 307,\n",
              " 'ven': 308,\n",
              " 'con': 309,\n",
              " 'hen': 310,\n",
              " 'fa': 311,\n",
              " 'And': 312,\n",
              " 'pa': 313,\n",
              " 'room': 314,\n",
              " 'wor': 315,\n",
              " 'di': 316,\n",
              " 'try': 317,\n",
              " '..': 318,\n",
              " '00': 319,\n",
              " 'really': 320,\n",
              " 'ation': 321,\n",
              " 'This': 322,\n",
              " 'ate': 323,\n",
              " 'by': 324,\n",
              " 'pl': 325,\n",
              " 'them': 326,\n",
              " 'per': 327,\n",
              " 'ous': 328,\n",
              " 'wo': 329,\n",
              " 'ten': 330,\n",
              " 'ess': 331,\n",
              " 'own': 332,\n",
              " 'May': 333,\n",
              " 'der': 334,\n",
              " 'going': 335,\n",
              " 'red': 336,\n",
              " 'hy': 337,\n",
              " 'uan': 338,\n",
              " 'back': 339,\n",
              " 'rom': 340,\n",
              " 'ga': 341,\n",
              " 'how': 342,\n",
              " 'off': 343,\n",
              " 'bo': 344,\n",
              " 'Would': 345,\n",
              " 'got': 346,\n",
              " 'tle': 347,\n",
              " 'They': 348,\n",
              " 'over': 349,\n",
              " 'Ch': 350,\n",
              " 'from': 351,\n",
              " 'ber': 352,\n",
              " 'ty': 353,\n",
              " 'br': 354,\n",
              " 'spe': 355,\n",
              " 'ep': 356,\n",
              " 'min': 357,\n",
              " 'us': 358,\n",
              " 'make': 359,\n",
              " 'ca': 360,\n",
              " 'other': 361,\n",
              " 'mor': 362,\n",
              " 'ough': 363,\n",
              " 'reat': 364,\n",
              " 'read': 365,\n",
              " 'fri': 366,\n",
              " 'ish': 367,\n",
              " 'bus': 368,\n",
              " 'pay': 369,\n",
              " 'sorry': 370,\n",
              " 'ity': 371,\n",
              " 'does': 372,\n",
              " 'ange': 373,\n",
              " 'ese': 374,\n",
              " 'new': 375,\n",
              " 'pre': 376,\n",
              " 'king': 377,\n",
              " 'Are': 378,\n",
              " 'ig': 379,\n",
              " 'anything': 380,\n",
              " 'ree': 381,\n",
              " 'then': 382,\n",
              " 'two': 383,\n",
              " 'call': 384,\n",
              " 'did': 385,\n",
              " 'har': 386,\n",
              " 'rice': 387,\n",
              " 'table': 388,\n",
              " 'ait': 389,\n",
              " 'give': 390,\n",
              " 'kind': 391,\n",
              " 'only': 392,\n",
              " 'There': 393,\n",
              " 'minut': 394,\n",
              " 'lit': 395,\n",
              " 'Chin': 396,\n",
              " 'tra': 397,\n",
              " 'yuan': 398,\n",
              " 'bet': 399,\n",
              " 'mad': 400,\n",
              " 'op': 401,\n",
              " 'So': 402,\n",
              " 'cour': 403,\n",
              " 'ater': 404,\n",
              " 'let': 405,\n",
              " 'ars': 406,\n",
              " 'irst': 407,\n",
              " 'Could': 408,\n",
              " 'pi': 409,\n",
              " 'tion': 410,\n",
              " 'lot': 411,\n",
              " 'tell': 412,\n",
              " 'sure': 413,\n",
              " 'Good': 414,\n",
              " 'long': 415,\n",
              " 'ac': 416,\n",
              " 'put': 417,\n",
              " 'und': 418,\n",
              " 'food': 419,\n",
              " 'has': 420,\n",
              " 'little': 421,\n",
              " 'course': 422,\n",
              " 'mon': 423,\n",
              " 'na': 424,\n",
              " 'col': 425,\n",
              " 'fo': 426,\n",
              " 'ving': 427,\n",
              " 'ard': 428,\n",
              " 'urn': 429,\n",
              " 'tr': 430,\n",
              " 'when': 431,\n",
              " 'lease': 432,\n",
              " 'He': 433,\n",
              " 'hich': 434,\n",
              " 'If': 435,\n",
              " 'cou': 436,\n",
              " 'price': 437,\n",
              " 'ort': 438,\n",
              " 'else': 439,\n",
              " 'even': 440,\n",
              " 'rink': 441,\n",
              " 'ze': 442,\n",
              " 'cial': 443,\n",
              " 'ise': 444,\n",
              " 'well': 445,\n",
              " 'down': 446,\n",
              " 'ning': 447,\n",
              " 'eat': 448,\n",
              " 'end': 449,\n",
              " 'ave': 450,\n",
              " 'ople': 451,\n",
              " 'atch': 452,\n",
              " 'could': 453,\n",
              " 'find': 454,\n",
              " 'wee': 455,\n",
              " 'blem': 456,\n",
              " 'problem': 457,\n",
              " 'gu': 458,\n",
              " 'Ok': 459,\n",
              " 'Thanks': 460,\n",
              " 'Why': 461,\n",
              " 'able': 462,\n",
              " 'something': 463,\n",
              " 'every': 464,\n",
              " 'after': 465,\n",
              " 'All': 466,\n",
              " 'her': 467,\n",
              " 'tain': 468,\n",
              " 'drink': 469,\n",
              " 'change': 470,\n",
              " 'where': 471,\n",
              " 'ket': 472,\n",
              " 'eah': 473,\n",
              " 'work': 474,\n",
              " 'clo': 475,\n",
              " 'An': 476,\n",
              " 'Where': 477,\n",
              " 'first': 478,\n",
              " 'better': 479,\n",
              " 'Please': 480,\n",
              " 'show': 481,\n",
              " 'Ex': 482,\n",
              " 'les': 483,\n",
              " 'today': 484,\n",
              " 'lf': 485,\n",
              " 'ress': 486,\n",
              " 'ye': 487,\n",
              " 'people': 488,\n",
              " 'doll': 489,\n",
              " 'made': 490,\n",
              " 'nice': 491,\n",
              " 'she': 492,\n",
              " 'oney': 493,\n",
              " 'ular': 494,\n",
              " 'ast': 495,\n",
              " 'lu': 496,\n",
              " 'xt': 497,\n",
              " 'minutes': 498,\n",
              " 'cle': 499,\n",
              " 'ist': 500,\n",
              " 'order': 501,\n",
              " 'ounds': 502,\n",
              " 'ser': 503,\n",
              " 'sha': 504,\n",
              " 'next': 505,\n",
              " 'umber': 506,\n",
              " 'ies': 507,\n",
              " 'looking': 508,\n",
              " 'many': 509,\n",
              " 'Chinese': 510,\n",
              " 'won': 511,\n",
              " 'ouse': 512,\n",
              " '...': 513,\n",
              " 'wait': 514,\n",
              " 'thank': 515,\n",
              " 'its': 516,\n",
              " 'also': 517,\n",
              " 'play': 518,\n",
              " 'ready': 519,\n",
              " 'great': 520,\n",
              " 'ting': 521,\n",
              " 'ang': 522,\n",
              " 'ste': 523,\n",
              " 'artment': 524,\n",
              " 'Yeah': 525,\n",
              " 'My': 526,\n",
              " 'number': 527,\n",
              " 'sk': 528,\n",
              " 'stop': 529,\n",
              " 'par': 530,\n",
              " 'him': 531,\n",
              " 'fore': 532,\n",
              " 'check': 533,\n",
              " 'ought': 534,\n",
              " 'tic': 535,\n",
              " 'mean': 536,\n",
              " 'sp': 537,\n",
              " 'most': 538,\n",
              " 'raid': 539,\n",
              " 'afraid': 540,\n",
              " 'week': 541,\n",
              " 'im': 542,\n",
              " 'row': 543,\n",
              " 'Re': 544,\n",
              " 'may': 545,\n",
              " 'wr': 546,\n",
              " 'month': 547,\n",
              " 'gl': 548,\n",
              " 'ner': 549,\n",
              " 'special': 550,\n",
              " 'dollars': 551,\n",
              " 'Of': 552,\n",
              " 'cuse': 553,\n",
              " 'pla': 554,\n",
              " 'say': 555,\n",
              " 'ide': 556,\n",
              " 'Don': 557,\n",
              " 'house': 558,\n",
              " 'Any': 559,\n",
              " 'ance': 560,\n",
              " 'turn': 561,\n",
              " 'sty': 562,\n",
              " 'ked': 563,\n",
              " 'these': 564,\n",
              " 'size': 565,\n",
              " 'inter': 566,\n",
              " 'shop': 567,\n",
              " 'color': 568,\n",
              " 'bit': 569,\n",
              " 'ph': 570,\n",
              " 'Okay': 571,\n",
              " 'been': 572,\n",
              " 'Excuse': 573,\n",
              " 'gg': 574,\n",
              " 'keep': 575,\n",
              " 'dif': 576,\n",
              " 'hour': 577,\n",
              " 'kes': 578,\n",
              " 'before': 579,\n",
              " 'friend': 580,\n",
              " 'pt': 581,\n",
              " 'ru': 582,\n",
              " 'card': 583,\n",
              " 'cre': 584,\n",
              " 'cent': 585,\n",
              " 'than': 586,\n",
              " 'deli': 587,\n",
              " 'morning': 588,\n",
              " 'name': 589,\n",
              " 'dress': 590,\n",
              " 'ff': 591,\n",
              " 'apartment': 592,\n",
              " 'Have': 593,\n",
              " 'din': 594,\n",
              " 'line': 595,\n",
              " 'te': 596,\n",
              " 'mend': 597,\n",
              " 'choo': 598,\n",
              " 'last': 599,\n",
              " 'quite': 600,\n",
              " 'diff': 601,\n",
              " 'fu': 602,\n",
              " 'mer': 603,\n",
              " 'home': 604,\n",
              " 'ger': 605,\n",
              " 'cost': 606,\n",
              " 'Then': 607,\n",
              " 'feel': 608,\n",
              " 'commend': 609,\n",
              " 'into': 610,\n",
              " 'had': 611,\n",
              " 'things': 612,\n",
              " 'sm': 613,\n",
              " 'recommend': 614,\n",
              " 'must': 615,\n",
              " 'sit': 616,\n",
              " 'cause': 617,\n",
              " 'ak': 618,\n",
              " 'fee': 619,\n",
              " 'gain': 620,\n",
              " 'Mo': 621,\n",
              " 'yes': 622,\n",
              " 'never': 623,\n",
              " 'Just': 624,\n",
              " 'du': 625,\n",
              " 'low': 626,\n",
              " 'sing': 627,\n",
              " 'ask': 628,\n",
              " 'money': 629,\n",
              " 'ping': 630,\n",
              " 'men': 631,\n",
              " 'sive': 632,\n",
              " 'dri': 633,\n",
              " 'fine': 634,\n",
              " 'gr': 635,\n",
              " 'who': 636,\n",
              " 'erc': 637,\n",
              " 'idea': 638,\n",
              " 'St': 639,\n",
              " 'alk': 640,\n",
              " 'same': 641,\n",
              " 'pet': 642,\n",
              " 'ton': 643,\n",
              " 'rece': 644,\n",
              " 'few': 645,\n",
              " 'ick': 646,\n",
              " 'watch': 647,\n",
              " 'bea': 648,\n",
              " 'hand': 649,\n",
              " 'hap': 650,\n",
              " 'ass': 651,\n",
              " 'Sorry': 652,\n",
              " 'offee': 653,\n",
              " 'cor': 654,\n",
              " 'care': 655,\n",
              " 'sta': 656,\n",
              " 'phone': 657,\n",
              " 'Hell': 658,\n",
              " 'Will': 659,\n",
              " 'best': 660,\n",
              " 'pie': 661,\n",
              " 'When': 662,\n",
              " 'still': 663,\n",
              " 'expen': 664,\n",
              " 'exerc': 665,\n",
              " 'Hello': 666,\n",
              " 'big': 667,\n",
              " 'man': 668,\n",
              " 'around': 669,\n",
              " 'high': 670,\n",
              " 'bring': 671,\n",
              " 'beaut': 672,\n",
              " 'fer': 673,\n",
              " 'Really': 674,\n",
              " 'wrong': 675,\n",
              " 'char': 676,\n",
              " 'ms': 677,\n",
              " 'mar': 678,\n",
              " 'enough': 679,\n",
              " 'bed': 680,\n",
              " 'Which': 681,\n",
              " 'ft': 682,\n",
              " 'stu': 683,\n",
              " 'start': 684,\n",
              " 'hile': 685,\n",
              " 'cut': 686,\n",
              " 'jo': 687,\n",
              " 'oup': 688,\n",
              " 'self': 689,\n",
              " 'ways': 690,\n",
              " 'differe': 691,\n",
              " 'coffee': 692,\n",
              " 'eas': 693,\n",
              " 'lar': 694,\n",
              " 'ose': 695,\n",
              " 'ue': 696,\n",
              " 'mes': 697,\n",
              " 'aper': 698,\n",
              " 'expensive': 699,\n",
              " 'In': 700,\n",
              " 'fit': 701,\n",
              " 'ful': 702,\n",
              " 'ertain': 703,\n",
              " 'irt': 704,\n",
              " 'fast': 705,\n",
              " 'doesn': 706,\n",
              " '50': 707,\n",
              " 'ces': 708,\n",
              " 'looks': 709,\n",
              " 'TV': 710,\n",
              " 'ves': 711,\n",
              " 'bad': 712,\n",
              " 'ction': 713,\n",
              " 'hot': 714,\n",
              " 'mind': 715,\n",
              " 'int': 716,\n",
              " 'rent': 717,\n",
              " 'send': 718,\n",
              " 'stea': 719,\n",
              " 'ertainly': 720,\n",
              " 'des': 721,\n",
              " 'tri': 722,\n",
              " 'reet': 723,\n",
              " 'cat': 724,\n",
              " 'mat': 725,\n",
              " 'old': 726,\n",
              " 'light': 727,\n",
              " 'cook': 728,\n",
              " 'ie': 729,\n",
              " 'were': 730,\n",
              " 'cho': 731,\n",
              " 'alth': 732,\n",
              " 'Anything': 733,\n",
              " 'mis': 734,\n",
              " 'which': 735,\n",
              " 'pend': 736,\n",
              " 'morrow': 737,\n",
              " 'bre': 738,\n",
              " 'vor': 739,\n",
              " 'while': 740,\n",
              " 'cond': 741,\n",
              " 'small': 742,\n",
              " 'his': 743,\n",
              " 'ones': 744,\n",
              " 'three': 745,\n",
              " 'ins': 746,\n",
              " 'ered': 747,\n",
              " 'love': 748,\n",
              " 'mail': 749,\n",
              " 'count': 750,\n",
              " 'Look': 751,\n",
              " 'Not': 752,\n",
              " 'dy': 753,\n",
              " 'sounds': 754,\n",
              " 'soup': 755,\n",
              " 'ken': 756,\n",
              " 'because': 757,\n",
              " 'thanks': 758,\n",
              " 'ild': 759,\n",
              " 'tea': 760,\n",
              " 'another': 761,\n",
              " 'ition': 762,\n",
              " 'always': 763,\n",
              " 'iful': 764,\n",
              " 'pair': 765,\n",
              " 'clean': 766,\n",
              " 'beautiful': 767,\n",
              " 'Did': 768,\n",
              " 'tor': 769,\n",
              " 'form': 770,\n",
              " 'weight': 771,\n",
              " 'style': 772,\n",
              " 'wine': 773,\n",
              " 'those': 774,\n",
              " 'suit': 775,\n",
              " 'Maybe': 776,\n",
              " 'place': 777,\n",
              " 'To': 778,\n",
              " 'tomorrow': 779,\n",
              " 'store': 780,\n",
              " 'diet': 781,\n",
              " 'interest': 782,\n",
              " 'dinner': 783,\n",
              " 'cu': 784,\n",
              " 'ever': 785,\n",
              " 'five': 786,\n",
              " 'lat': 787,\n",
              " 'vice': 788,\n",
              " 'Certainly': 789,\n",
              " 'Mr': 790,\n",
              " 'age': 791,\n",
              " 'dis': 792,\n",
              " 'usu': 793,\n",
              " 'Co': 794,\n",
              " 'night': 795,\n",
              " 'went': 796,\n",
              " 'reg': 797,\n",
              " 'health': 798,\n",
              " 'lack': 799,\n",
              " 'sale': 800,\n",
              " 'Be': 801,\n",
              " 'mm': 802,\n",
              " 'why': 803,\n",
              " 'hard': 804,\n",
              " 'shopping': 805,\n",
              " 'ear': 806,\n",
              " 'fin': 807,\n",
              " 'port': 808,\n",
              " 'recei': 809,\n",
              " 'Hi': 810,\n",
              " 'av': 811,\n",
              " 'free': 812,\n",
              " 'lcome': 813,\n",
              " 'ash': 814,\n",
              " 'Your': 815,\n",
              " 'moment': 816,\n",
              " 'comes': 817,\n",
              " 'noon': 818,\n",
              " 'prefer': 819,\n",
              " 'act': 820,\n",
              " 'cur': 821,\n",
              " 'charge': 822,\n",
              " 'again': 823,\n",
              " 'walk': 824,\n",
              " 'pop': 825,\n",
              " '10': 826,\n",
              " 'Ta': 827,\n",
              " 'air': 828,\n",
              " 'hite': 829,\n",
              " 'ually': 830,\n",
              " 'left': 831,\n",
              " 'ary': 832,\n",
              " 'wear': 833,\n",
              " 'different': 834,\n",
              " '30': 835,\n",
              " 'book': 836,\n",
              " 'hund': 837,\n",
              " 'later': 838,\n",
              " 'didn': 839,\n",
              " 'hundred': 840,\n",
              " 'Now': 841,\n",
              " 'ee': 842,\n",
              " 'might': 843,\n",
              " 'ery': 844,\n",
              " 'set': 845,\n",
              " 'near': 846,\n",
              " 'receipt': 847,\n",
              " '20': 848,\n",
              " 'For': 849,\n",
              " 'sal': 850,\n",
              " 'tal': 851,\n",
              " 'vers': 852,\n",
              " 'isn': 853,\n",
              " 'each': 854,\n",
              " 'used': 855,\n",
              " 'exercise': 856,\n",
              " 'mi': 857,\n",
              " 'swe': 858,\n",
              " 'schoo': 859,\n",
              " 'sell': 860,\n",
              " 'ality': 861,\n",
              " 'urant': 862,\n",
              " 'produ': 863,\n",
              " 'wonder': 864,\n",
              " 'school': 865,\n",
              " 'done': 866,\n",
              " 'dish': 867,\n",
              " 'ily': 868,\n",
              " 'mil': 869,\n",
              " 'wind': 870,\n",
              " 'run': 871,\n",
              " 'sed': 872,\n",
              " 'clu': 873,\n",
              " 'fre': 874,\n",
              " 'oes': 875,\n",
              " 'pr': 876,\n",
              " 'lie': 877,\n",
              " 'soon': 878,\n",
              " 'favor': 879,\n",
              " 'evening': 880,\n",
              " 'steak': 881,\n",
              " 'popular': 882,\n",
              " 'mp': 883,\n",
              " 'water': 884,\n",
              " 'xi': 885,\n",
              " 'road': 886,\n",
              " 'qui': 887,\n",
              " 'full': 888,\n",
              " 'By': 889,\n",
              " 'side': 890,\n",
              " 'She': 891,\n",
              " 'ag': 892,\n",
              " 'four': 893,\n",
              " 'top': 894,\n",
              " 'sub': 895,\n",
              " 'skin': 896,\n",
              " 'usually': 897,\n",
              " 'cr': 898,\n",
              " 'ans': 899,\n",
              " 'resta': 900,\n",
              " 'already': 901,\n",
              " 'move': 902,\n",
              " 'rather': 903,\n",
              " 'said': 904,\n",
              " 'guess': 905,\n",
              " 'restaurant': 906,\n",
              " 'Wait': 907,\n",
              " 'late': 908,\n",
              " 'person': 909,\n",
              " 'pic': 910,\n",
              " 'stay': 911,\n",
              " 'post': 912,\n",
              " 'afternoon': 913,\n",
              " 'year': 914,\n",
              " 'ffic': 915,\n",
              " 'Mom': 916,\n",
              " 'bot': 917,\n",
              " 'gar': 918,\n",
              " 'worry': 919,\n",
              " 'thought': 920,\n",
              " 'station': 921,\n",
              " 'often': 922,\n",
              " 'friends': 923,\n",
              " 'white': 924,\n",
              " 'dog': 925,\n",
              " 'taste': 926,\n",
              " 'market': 927,\n",
              " 'black': 928,\n",
              " 'fam': 929,\n",
              " 'flo': 930,\n",
              " 'real': 931,\n",
              " 'street': 932,\n",
              " 'lic': 933,\n",
              " 'traffic': 934,\n",
              " 'cream': 935,\n",
              " 'cents': 936,\n",
              " 'floor': 937,\n",
              " 'oun': 938,\n",
              " 'their': 939,\n",
              " 'mem': 940,\n",
              " 'stra': 941,\n",
              " 'half': 942,\n",
              " 'hed': 943,\n",
              " 'til': 944,\n",
              " 'quality': 945,\n",
              " 'cious': 946,\n",
              " 'reser': 947,\n",
              " 'body': 948,\n",
              " 'Ab': 949,\n",
              " 'da': 950,\n",
              " 'ring': 951,\n",
              " 'yet': 952,\n",
              " 'stand': 953,\n",
              " 'hair': 954,\n",
              " 'unch': 955,\n",
              " 'bir': 956,\n",
              " 'cal': 957,\n",
              " 'far': 958,\n",
              " 'doing': 959,\n",
              " 'six': 960,\n",
              " 'days': 961,\n",
              " 'China': 962,\n",
              " 'bedroom': 963,\n",
              " 'Dad': 964,\n",
              " 'less': 965,\n",
              " 'ps': 966,\n",
              " 'ture': 967,\n",
              " 'such': 968,\n",
              " 'times': 969,\n",
              " 'window': 970,\n",
              " 'Al': 971,\n",
              " 'bro': 972,\n",
              " 'bought': 973,\n",
              " 'cid': 974,\n",
              " 'hur': 975,\n",
              " 'open': 976,\n",
              " 'part': 977,\n",
              " 'chic': 978,\n",
              " 'asure': 979,\n",
              " 'build': 980,\n",
              " 'redit': 981,\n",
              " 'chicken': 982,\n",
              " 'bar': 983,\n",
              " 'bill': 984,\n",
              " 'cl': 985,\n",
              " 'rap': 986,\n",
              " 'until': 987,\n",
              " 'tonight': 988,\n",
              " 'easy': 989,\n",
              " 'product': 990,\n",
              " 'milk': 991,\n",
              " 'fresh': 992,\n",
              " '15': 993,\n",
              " 'credit': 994,\n",
              " 'fun': 995,\n",
              " 'lunch': 996,\n",
              " 'haven': 997,\n",
              " 'cell': 998,\n",
              " 'fect': 999,\n",
              " ...}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "63CrPUrEYrk6"
      },
      "outputs": [],
      "source": [
        "class UstaTokenizer:\n",
        "    def __init__(self, vocab):\n",
        "        self.vocab = vocab\n",
        "        self.reverse_vocab = {v: k for k, v in self.vocab.items()}\n",
        "\n",
        "        # √ñzel token'larƒ± kontrol et\n",
        "        self.unk_token = \"<unk>\" if \"<unk>\" in vocab else None\n",
        "        self.pad_token = \"<pad>\" if \"<pad>\" in vocab else None\n",
        "\n",
        "        # Bo≈üluk token'ƒ±nƒ± bul\n",
        "        self.space_token = None\n",
        "        if \" \" in vocab:\n",
        "            self.space_token = \" \"\n",
        "        elif \"ƒ†\" in vocab:  # GPT-2 style\n",
        "            self.space_token = \"ƒ†\"\n",
        "        elif \"‚ñÅ\" in vocab:  # SentencePiece style\n",
        "            self.space_token = \"‚ñÅ\"\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Bo≈üluk token'ƒ± bulunamadƒ±! Bo≈üluklar atlanacak.\")\n",
        "\n",
        "        # Vocab boyutunu kontrol et\n",
        "        print(f\"üìä Vocab boyutu: {len(self.vocab)}\")\n",
        "        print(f\"üîë Max token ID: {max(self.vocab.values()) if self.vocab else 0}\")\n",
        "\n",
        "        # √ñzel token'larƒ± yazdƒ±r\n",
        "        special_tokens = [k for k in vocab.keys() if k.startswith('<') and k.endswith('>')]\n",
        "        print(f\"üè∑Ô∏è √ñzel token'lar: {special_tokens}\")\n",
        "\n",
        "    def encode(self, text):\n",
        "        tokens = []\n",
        "\n",
        "        for word in text.split():\n",
        "            i = 0\n",
        "            while i < len(word):\n",
        "                found_match = False\n",
        "                # En uzun e≈üle≈ümeyi bul (greedy matching)\n",
        "                for j in range(len(word), i, -1):\n",
        "                    sub_word = word[i:j]\n",
        "                    if sub_word in self.vocab:\n",
        "                        tokens.append(self.vocab[sub_word])\n",
        "                        i = j\n",
        "                        found_match = True\n",
        "                        break\n",
        "\n",
        "                if not found_match:\n",
        "                    # Bilinmeyen token i√ßin kontrol\n",
        "                    if self.unk_token:\n",
        "                        tokens.append(self.vocab[self.unk_token])\n",
        "                    else:\n",
        "                        # Eƒüer <unk> yoksa, karakteri atla veya hata ver\n",
        "                        print(f\"‚ö†Ô∏è Bilinmeyen karakter: '{word[i]}' - atlanƒ±yor\")\n",
        "                    i += 1\n",
        "\n",
        "            # Bo≈üluk token'ƒ± varsa ekle (kelimeler arasƒ±)\n",
        "            if self.space_token:\n",
        "                tokens.append(self.vocab[self.space_token])\n",
        "\n",
        "        # Eƒüer text bo≈ülukla bitmiyorsa, son bo≈üluk token'ƒ±nƒ± kaldƒ±r\n",
        "        if not text.endswith(\" \") and tokens and self.space_token:\n",
        "            if tokens[-1] == self.vocab[self.space_token]:\n",
        "                tokens.pop()\n",
        "\n",
        "        return torch.tensor(tokens, dtype=torch.long)\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        token_ids = self.encode(text)\n",
        "        # Tensor'u listeye √ßevir\n",
        "        if hasattr(token_ids, 'detach'):\n",
        "            token_ids = token_ids.detach().cpu().numpy().tolist()\n",
        "        else:\n",
        "            token_ids = token_ids.tolist()\n",
        "\n",
        "        # ID'leri token'lara √ßevir\n",
        "        tokens = []\n",
        "        for id in token_ids:\n",
        "            if id in self.reverse_vocab:\n",
        "                tokens.append(self.reverse_vocab[id])\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Hata: ID {id} vocab'da bulunamadƒ±!\")\n",
        "                tokens.append(\"<unk>\")\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def decode(self, ids):\n",
        "        text = \"\"\n",
        "        for id in ids:\n",
        "            if isinstance(id, torch.Tensor):\n",
        "                id = id.item()\n",
        "\n",
        "            if id in self.reverse_vocab:\n",
        "                token = self.reverse_vocab[id]\n",
        "                # Bo≈üluk token'larƒ±nƒ± i≈üle\n",
        "                if token == self.space_token:\n",
        "                    text += \" \"\n",
        "                elif token.startswith(\"ƒ†\"):  # GPT-2 style\n",
        "                    text += \" \" + token[1:]\n",
        "                elif token.startswith(\"‚ñÅ\"):  # SentencePiece style\n",
        "                    text += \" \" + token[1:]\n",
        "                else:\n",
        "                    text += token\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Decode hatasƒ±: ID {id} bulunamadƒ±!\")\n",
        "                text += \"<unk>\"\n",
        "\n",
        "        return text.strip()\n",
        "\n",
        "    def get_vocab_info(self):\n",
        "        \"\"\"Vocab hakkƒ±nda detaylƒ± bilgi\"\"\"\n",
        "        print(f\"üìä Toplam vocab boyutu: {len(self.vocab)}\")\n",
        "        print(f\"üî¢ Token ID aralƒ±ƒüƒ±: 0 - {max(self.vocab.values())}\")\n",
        "        print(f\"üè∑Ô∏è √ñzel token sayƒ±sƒ±: {len([k for k in self.vocab if k.startswith('<')])}\")\n",
        "\n",
        "        # En sƒ±k kullanƒ±lan 10 token\n",
        "        sorted_vocab = sorted(self.vocab.items(), key=lambda x: x[1])[:10]\n",
        "        print(\"üîù ƒ∞lk 10 token:\")\n",
        "        for token, id in sorted_vocab:\n",
        "            print(f\"  {id}: '{token}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcUPJRJcAhFY",
        "outputId": "c05b745a-0e78-4126-ec04-ca76cbb3399e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Bo≈üluk token'ƒ± bulunamadƒ±! Bo≈üluklar atlanacak.\n",
            "üìä Vocab boyutu: 10500\n",
            "üîë Max token ID: 10499\n",
            "üè∑Ô∏è √ñzel token'lar: ['<unk>']\n"
          ]
        }
      ],
      "source": [
        "u_tokenizer = UstaTokenizer(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "k8AI9BYXa4X2"
      },
      "outputs": [],
      "source": [
        "def load_dataset_efficiently(dataset_path, max_chars=None):\n",
        "    \"\"\"Dataset'i memory efficient ≈üekilde y√ºkler\"\"\"\n",
        "    print(f\"Loading dataset from {dataset_path}...\")\n",
        "\n",
        "    try:\n",
        "        with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "            if max_chars:\n",
        "                text = f.read(max_chars)  # Sadece belirli miktarda oku\n",
        "                print(f\"‚úì Dataset loaded (first {max_chars} chars)\")\n",
        "            else:\n",
        "                text = f.read()\n",
        "                print(f\"‚úì Dataset loaded completely ({len(text)} chars)\")\n",
        "\n",
        "        return text\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå {dataset_path} not found!\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading dataset: {str(e)}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0UWU9Z2-hRS",
        "outputId": "8d661548-8593-4af6-bc79-e4cb34060075"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset from /content/dialogues.txt...\n",
            "‚úì Dataset loaded completely (1257133 chars)\n"
          ]
        }
      ],
      "source": [
        "text = load_dataset_efficiently(\"/content/dialogues.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek6iTN7wav5P"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGUQR0h2bkC-"
      },
      "source": [
        "# Embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ypBRYQsCNSRl"
      },
      "outputs": [],
      "source": [
        "def get_rotary_position_encoding(input, base=10000, device=None):\n",
        "    # Eƒüer device verilmezse input'un device'ƒ±nƒ± kullan\n",
        "    if device is None:\n",
        "        device = input.device\n",
        "\n",
        "    context_length, dimension = input.shape\n",
        "    assert dimension % 2 == 0, \"dimension must be even\"\n",
        "\n",
        "    half_dimension = dimension // 2\n",
        "    freqs_indices = torch.arange(0, half_dimension, device=device, dtype=torch.float32)\n",
        "    freqs = 1.0 / (base ** (freqs_indices / dimension))\n",
        "\n",
        "    positions = torch.arange(0, context_length, device=device, dtype=torch.float32).unsqueeze(1)\n",
        "    angles = positions * freqs\n",
        "\n",
        "    sin_angles = torch.sin(angles)\n",
        "    cos_angles = torch.cos(angles)\n",
        "\n",
        "    input_even = input[:, :dimension // 2]  # [0, 2, 4, ..]\n",
        "    input_odd = input[:, dimension // 2:]   # [1, 3, 5, ..]\n",
        "\n",
        "    input_even_rotated = input_even * cos_angles - input_odd * sin_angles\n",
        "    input_odd_rotated = input_even * sin_angles + input_odd * cos_angles\n",
        "\n",
        "    input_rotated = torch.empty_like(input, device=device)\n",
        "    input_rotated[:, :dimension // 2] = input_even_rotated\n",
        "    input_rotated[:, dimension // 2:] = input_odd_rotated\n",
        "\n",
        "    return input_rotated\n",
        "\n",
        "\n",
        "# Alternatif olarak, model i√ßinde √ßaƒüƒ±rƒ±rken device'ƒ± explicit ver:\n",
        "# rotary_output = get_rotary_position_encoding(x, device=x.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "otQ7BdmuNuII"
      },
      "outputs": [],
      "source": [
        "class UstaEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, context_length):\n",
        "        super().__init__()\n",
        "        # position embedding but not being used in the forward pass\n",
        "        # it is just for educational purposes\n",
        "        # self.pos_embedding = nn.Embedding(context_length, embedding_dim)\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.get_pos = get_rotary_position_encoding\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.get_pos(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjYrjJZacBQW"
      },
      "source": [
        "# Multi Head Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "p5jJ75SabxfT"
      },
      "outputs": [],
      "source": [
        "class UstaMultiHeadAttention(nn.Module):\n",
        "  def __init__(self, embedding_dim, output_dim, context_length, num_heads, dropout_rate = 0):\n",
        "    super().__init__()\n",
        "\n",
        "    self.context_length = context_length\n",
        "\n",
        "    self.multi_head_attention = nn.MultiheadAttention(embedding_dim, num_heads, dropout=dropout_rate)\n",
        "    self.projection = nn.Linear(embedding_dim, output_dim)\n",
        "\n",
        "    self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1).bool())\n",
        "\n",
        "  def forward(self, x):\n",
        "    number_of_tokens = x.shape[0]\n",
        "    x = x[:self.context_length]\n",
        "    attention_mask = self.mask[:number_of_tokens, :number_of_tokens]\n",
        "    out, _ = self.multi_head_attention(x, x, x, attn_mask=attention_mask)\n",
        "    out = self.projection(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOv0LmgPcnH-"
      },
      "source": [
        "# Layer Normalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "V_YPQa-ucmhv"
      },
      "outputs": [],
      "source": [
        "class UstaLayerNorm(nn.Module):\n",
        "  def __init__(self, embedding_dim, eps=1e-5):\n",
        "    super().__init__()\n",
        "    self.eps = eps\n",
        "\n",
        "    self.weight = nn.Parameter(torch.ones(embedding_dim))\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    mean = x.mean(dim=-1, keepdim=True)\n",
        "    variance = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "    normalized_x = (x - mean) / torch.sqrt(variance + self.eps)\n",
        "    return self.weight * normalized_x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qx8-73sc31L"
      },
      "source": [
        "# MLP Block\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zsHdjKmPc3PI"
      },
      "outputs": [],
      "source": [
        "class GELU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return 0.5 * x * (\n",
        "      1 + torch.tanh(\n",
        "          torch.sqrt(torch.tensor(2 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))\n",
        "        )\n",
        "    )\n",
        "\n",
        "class UstaMLP(nn.Module):\n",
        "  def __init__(self, embedding_dim, hidden_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.gate_proj = nn.Linear(embedding_dim, hidden_dim)\n",
        "    self.up_proj = nn.Linear(embedding_dim, hidden_dim)\n",
        "    self.down_proj = nn.Linear(hidden_dim, embedding_dim)\n",
        "    self.gelu = GELU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\" gate = self.gate_proj(x)\n",
        "        gate = F.gelu(gate, approximate=\"tanh\")\n",
        "        up = self.up_proj(x)\n",
        "        fuse = gate * up\n",
        "        outputs = self.down_proj(fuse) \"\"\"\n",
        "    gate = self.gate_proj(x)\n",
        "    gate = self.gelu(gate)\n",
        "    up = self.up_proj(x)\n",
        "    fuse = gate * up\n",
        "    outputs = self.down_proj(fuse)\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1nPXKqbcYIn"
      },
      "source": [
        "# Decoder Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JiD_kEdicXPT"
      },
      "outputs": [],
      "source": [
        "class UstaDecoderBlock(nn.Module):\n",
        "  def __init__(self, embedding_dim, num_heads, context_length):\n",
        "    super().__init__()\n",
        "\n",
        "    self.self_attention = UstaMultiHeadAttention(embedding_dim, embedding_dim, context_length, num_heads, dropout_rate=0.5)\n",
        "    self.norm1 = UstaLayerNorm(embedding_dim)\n",
        "    self.mlp = UstaMLP(embedding_dim, embedding_dim)\n",
        "    self.norm2 = UstaLayerNorm(embedding_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    res = self.norm1(x)\n",
        "\n",
        "    x = self.self_attention(x)\n",
        "    x = self.norm1(x)\n",
        "\n",
        "    x = x + res\n",
        "\n",
        "    res = self.norm2(x)\n",
        "    x = self.mlp(x)\n",
        "    x = self.norm2(x)\n",
        "\n",
        "    x = x + res\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpUxz8FvdEHO"
      },
      "source": [
        "# Model Construction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5js1_TtJcXT-"
      },
      "outputs": [],
      "source": [
        "class UstaModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, num_heads, context_length, num_layers):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding = UstaEmbedding(vocab_size, embedding_dim, context_length)\n",
        "    self.layers = nn.Sequential(\n",
        "      *[UstaDecoderBlock(embedding_dim, num_heads, context_length) for _ in range(num_layers)]\n",
        "    )\n",
        "\n",
        "    self.lm_head = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    x = self.embedding(x) # dictionary meaning of the tokens (words)\n",
        "\n",
        "    x = self.layers(x)\n",
        "    x = self.lm_head(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "  \"\"\" out = u_model(torch.tensor(new_tokens))\n",
        "\n",
        "  probs = torch.softmax(out[-1], dim=-1)\n",
        "  max_prob, max_index = torch.max(probs, dim=-1)\n",
        "  max_prob, max_index, probs\n",
        "  \"\"\"\n",
        "\n",
        "  def generate(self, x: torch.Tensor, max_new_tokens: int): # top_k, top_p, temperature\n",
        "    tokens = x.detach().cpu().numpy().tolist()\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "      out = self.forward(x)\n",
        "      probs = torch.softmax(out[-1], dim=-1)\n",
        "      _, max_index = torch.max(probs, dim=-1)\n",
        "      tokens.append(max_index.item())\n",
        "      if max_index == 59 or len(tokens) > 32: # <eos> and max context length\n",
        "        break\n",
        "\n",
        "      x = torch.tensor(tokens)\n",
        "\n",
        "    return tokens\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1it3g95BeflL"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_lM6gXQddv5h"
      },
      "outputs": [],
      "source": [
        "context_length = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJK5gD7vBVMD",
        "outputId": "a678e4ad-6a55-42b2-e53f-a0c125511949"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Bo≈üluk token'ƒ± bulunamadƒ±! Bo≈üluklar atlanacak.\n",
            "üìä Vocab boyutu: 10500\n",
            "üîë Max token ID: 10499\n",
            "üè∑Ô∏è √ñzel token'lar: ['<unk>']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([  98, 5516,  120,   98, 4547,  149])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "u_tokenizer = UstaTokenizer(vocab)\n",
        "\n",
        "prompt = \"the capital of the united\"\n",
        "\n",
        "tokens = u_tokenizer.encode(prompt)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zOWNy-oZdxXe"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "u_model = UstaModel(vocab_size=len(u_tokenizer.vocab), embedding_dim=12, num_heads=4, context_length=context_length, num_layers=8)\n",
        "\n",
        "# Use the first input from the dataset for the forward pass\n",
        "# out = u_model(dataset.inputs[0])\n",
        "# out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQmS4hGpeCPi",
        "outputId": "b4648b18-25a4-4f97-b9cd-c22c37bd9cb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(315507, torch.Tensor)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token_ids = u_tokenizer.encode(text)\n",
        "len(token_ids), type(token_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fdjz3pc8eFuO",
        "outputId": "4eeb24ec-d2a9-4f60-d8dd-1f374db3124a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(315507, list)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ids = token_ids.detach().cpu().numpy().tolist()\n",
        "len(ids), type(ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YazxuqrJeWSZ"
      },
      "source": [
        "# Text Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KZQMCrKLeMuE"
      },
      "outputs": [],
      "source": [
        "pad_id = 63\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "  def __init__(self, token_ids: list, context_length: int, stride: int):\n",
        "    super().__init__()\n",
        "\n",
        "    self.inputs = []\n",
        "    self.targets = []\n",
        "\n",
        "    for i in range(0, len(token_ids) - context_length, stride):\n",
        "      input_chunk = token_ids[i:i + context_length]\n",
        "      target_chunk = token_ids[i + 1:i + context_length + 1]\n",
        "\n",
        "      # truncate to context length\n",
        "      input_chunk = input_chunk[:context_length]\n",
        "      target_chunk = target_chunk[:context_length]\n",
        "\n",
        "      # pad to context length\n",
        "      input_chunk = input_chunk + [pad_id] * (context_length - len(input_chunk))\n",
        "      target_chunk = target_chunk + [pad_id] * (context_length - len(target_chunk))\n",
        "\n",
        "      # truncate to context length\n",
        "      input_chunk = input_chunk[:context_length]\n",
        "      target_chunk = target_chunk[:context_length]\n",
        "\n",
        "      self.inputs.append(torch.tensor(input_chunk, dtype=torch.long))\n",
        "      self.targets.append(torch.tensor(target_chunk, dtype=torch.long))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.inputs)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.inputs[idx], self.targets[idx]\n",
        "\n",
        "\n",
        "def create_data_loader(token_ids: list, context_length: int, stride: int,\n",
        "                       batch_size: int, shuffle: bool = True, device: str = \"cpu\"):\n",
        "  dataset = TextDataset(token_ids, context_length, stride)\n",
        "  dataloader = DataLoader(\n",
        "      dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=shuffle,\n",
        "      generator=torch.Generator(device=device)\n",
        "    )\n",
        "\n",
        "  return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDZdFy3set9f",
        "outputId": "73c14f37-cb16-4b75-f08d-9841665b1eff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(26290, 26290)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stride = 12\n",
        "\n",
        "dataset = TextDataset(ids, context_length, stride)\n",
        "\n",
        "len(dataset.inputs), len(dataset.targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jq9KvbHeezwF",
        "outputId": "672e06e1-2b3a-4602-b95f-ed3ae08557cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "272676\n",
            "UstaModel(\n",
            "  (embedding): UstaEmbedding(\n",
            "    (embedding): Embedding(10500, 12)\n",
            "  )\n",
            "  (layers): Sequential(\n",
            "    (0): UstaDecoderBlock(\n",
            "      (self_attention): UstaMultiHeadAttention(\n",
            "        (multi_head_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
            "        )\n",
            "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
            "      )\n",
            "      (norm1): UstaLayerNorm()\n",
            "      (mlp): UstaMLP(\n",
            "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (gelu): GELU()\n",
            "      )\n",
            "      (norm2): UstaLayerNorm()\n",
            "    )\n",
            "    (1): UstaDecoderBlock(\n",
            "      (self_attention): UstaMultiHeadAttention(\n",
            "        (multi_head_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
            "        )\n",
            "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
            "      )\n",
            "      (norm1): UstaLayerNorm()\n",
            "      (mlp): UstaMLP(\n",
            "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (gelu): GELU()\n",
            "      )\n",
            "      (norm2): UstaLayerNorm()\n",
            "    )\n",
            "    (2): UstaDecoderBlock(\n",
            "      (self_attention): UstaMultiHeadAttention(\n",
            "        (multi_head_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
            "        )\n",
            "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
            "      )\n",
            "      (norm1): UstaLayerNorm()\n",
            "      (mlp): UstaMLP(\n",
            "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (gelu): GELU()\n",
            "      )\n",
            "      (norm2): UstaLayerNorm()\n",
            "    )\n",
            "    (3): UstaDecoderBlock(\n",
            "      (self_attention): UstaMultiHeadAttention(\n",
            "        (multi_head_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
            "        )\n",
            "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
            "      )\n",
            "      (norm1): UstaLayerNorm()\n",
            "      (mlp): UstaMLP(\n",
            "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (gelu): GELU()\n",
            "      )\n",
            "      (norm2): UstaLayerNorm()\n",
            "    )\n",
            "    (4): UstaDecoderBlock(\n",
            "      (self_attention): UstaMultiHeadAttention(\n",
            "        (multi_head_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
            "        )\n",
            "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
            "      )\n",
            "      (norm1): UstaLayerNorm()\n",
            "      (mlp): UstaMLP(\n",
            "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (gelu): GELU()\n",
            "      )\n",
            "      (norm2): UstaLayerNorm()\n",
            "    )\n",
            "    (5): UstaDecoderBlock(\n",
            "      (self_attention): UstaMultiHeadAttention(\n",
            "        (multi_head_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
            "        )\n",
            "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
            "      )\n",
            "      (norm1): UstaLayerNorm()\n",
            "      (mlp): UstaMLP(\n",
            "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (gelu): GELU()\n",
            "      )\n",
            "      (norm2): UstaLayerNorm()\n",
            "    )\n",
            "    (6): UstaDecoderBlock(\n",
            "      (self_attention): UstaMultiHeadAttention(\n",
            "        (multi_head_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
            "        )\n",
            "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
            "      )\n",
            "      (norm1): UstaLayerNorm()\n",
            "      (mlp): UstaMLP(\n",
            "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (gelu): GELU()\n",
            "      )\n",
            "      (norm2): UstaLayerNorm()\n",
            "    )\n",
            "    (7): UstaDecoderBlock(\n",
            "      (self_attention): UstaMultiHeadAttention(\n",
            "        (multi_head_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
            "        )\n",
            "        (projection): Linear(in_features=12, out_features=12, bias=True)\n",
            "      )\n",
            "      (norm1): UstaLayerNorm()\n",
            "      (mlp): UstaMLP(\n",
            "        (gate_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (up_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (down_proj): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (gelu): GELU()\n",
            "      )\n",
            "      (norm2): UstaLayerNorm()\n",
            "    )\n",
            "  )\n",
            "  (lm_head): Linear(in_features=12, out_features=10500, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# model parameters count\n",
        "parameters_count = sum(p.numel() for p in u_model.parameters())\n",
        "print(parameters_count)\n",
        "\n",
        "# model architecture\n",
        "print(u_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wafz6_67fDZd",
        "outputId": "5840c4e4-3320-421a-b336-5b3c4c068c5e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 10500])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out0 = u_model(dataset.inputs[0])\n",
        "out0.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzESqr1RfMSw"
      },
      "source": [
        "# Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-zRa0u8sfEmP"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9u0KgOtfEjP",
        "outputId": "6b5575c0-0c9e-4105-b647-07125f9c8e14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(9.8345, grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss = loss_fn(out0, dataset.targets[0])\n",
        "loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feX8B-_lfQtf"
      },
      "source": [
        "# Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "sU9hi3aMfEgj"
      },
      "outputs": [],
      "source": [
        "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "optimizer = torch.optim.AdamW(u_model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vruukUBfEeg",
        "outputId": "736b714e-0433-4cf1-9ff3-bd57e747eb68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32]) torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "for input, target in dataset:\n",
        "  print(input.shape, target.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbf_RPDzrrhu",
        "outputId": "6a1f8439-8aae-46be-a743-9aa165813931"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# √ñNEMLƒ∞: Model GPU'ya ta≈üƒ±\n",
        "u_model = u_model.to(device)\n",
        "print(f\"Model device: {next(u_model.parameters()).device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l6jCrE1OPNZx",
        "outputId": "b36b963c-074b-4aae-9455-8fc251e1f947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset boyutu: 26290\n",
            "Ba≈ülangƒ±√ß epochs: 20\n",
            "Early stopping: 10 epoch patience\n",
            "\n",
            "üöÄ EPOCH 1/20\n",
            "  Batch 0, Loss: 9.7664\n",
            "  Batch 2000, Loss: 6.6966\n",
            "  Batch 4000, Loss: 5.1715\n",
            "  Batch 6000, Loss: 4.4472\n",
            "  Batch 8000, Loss: 4.7425\n",
            "  Batch 10000, Loss: 6.2761\n",
            "  Batch 12000, Loss: 3.8171\n",
            "  Batch 14000, Loss: 4.3354\n",
            "  Batch 16000, Loss: 3.7717\n",
            "  Batch 18000, Loss: 3.9750\n",
            "  Batch 20000, Loss: 3.8769\n",
            "  Batch 22000, Loss: 5.7618\n",
            "  Batch 24000, Loss: 3.1998\n",
            "  Batch 26000, Loss: 3.8308\n",
            "‚úÖ Epoch 1 - Avg Loss: 4.9935 (1034.1s)\n",
            "üéØ En iyi loss g√ºncellendi: 4.9935\n",
            "\n",
            "üöÄ EPOCH 2/20\n",
            "  Batch 0, Loss: 4.3394\n",
            "  Batch 2000, Loss: 5.6512\n",
            "  Batch 4000, Loss: 4.3718\n",
            "  Batch 6000, Loss: 3.1673\n",
            "  Batch 8000, Loss: 3.9403\n",
            "  Batch 10000, Loss: 5.6180\n",
            "  Batch 12000, Loss: 2.8368\n",
            "  Batch 14000, Loss: 4.0642\n",
            "  Batch 16000, Loss: 3.5127\n",
            "  Batch 18000, Loss: 3.6819\n",
            "  Batch 20000, Loss: 3.3463\n",
            "  Batch 22000, Loss: 5.4762\n",
            "  Batch 24000, Loss: 3.2213\n",
            "  Batch 26000, Loss: 3.5731\n",
            "‚úÖ Epoch 2 - Avg Loss: 4.4370 (1032.7s)\n",
            "üéØ En iyi loss g√ºncellendi: 4.4370\n",
            "\n",
            "üöÄ EPOCH 3/20\n",
            "  Batch 0, Loss: 4.3086\n",
            "  Batch 2000, Loss: 5.4862\n",
            "  Batch 4000, Loss: 4.2464\n",
            "  Batch 6000, Loss: 2.8583\n",
            "  Batch 8000, Loss: 3.4808\n",
            "  Batch 10000, Loss: 6.0232\n",
            "  Batch 12000, Loss: 2.8753\n",
            "  Batch 14000, Loss: 3.8401\n",
            "  Batch 16000, Loss: 3.2395\n",
            "  Batch 18000, Loss: 3.4309\n",
            "  Batch 20000, Loss: 3.1116\n",
            "  Batch 22000, Loss: 5.4686\n",
            "  Batch 24000, Loss: 3.1506\n",
            "  Batch 26000, Loss: 3.4946\n",
            "‚úÖ Epoch 3 - Avg Loss: 4.2760 (1042.2s)\n",
            "üéØ En iyi loss g√ºncellendi: 4.2760\n",
            "üìà Loss d√ºzenli d√º≈ü√ºyor, devam et!\n",
            "\n",
            "üöÄ EPOCH 4/20\n",
            "  Batch 0, Loss: 4.1981\n",
            "  Batch 2000, Loss: 5.4381\n",
            "  Batch 4000, Loss: 4.0552\n",
            "  Batch 6000, Loss: 2.8238\n",
            "  Batch 8000, Loss: 3.5009\n",
            "  Batch 10000, Loss: 6.0655\n",
            "  Batch 12000, Loss: 2.7897\n",
            "  Batch 14000, Loss: 3.7442\n",
            "  Batch 16000, Loss: 3.1967\n",
            "  Batch 18000, Loss: 3.2915\n",
            "  Batch 20000, Loss: 2.9921\n",
            "  Batch 22000, Loss: 5.2647\n",
            "  Batch 24000, Loss: 2.9885\n",
            "  Batch 26000, Loss: 3.2093\n",
            "‚úÖ Epoch 4 - Avg Loss: 4.1814 (1037.5s)\n",
            "üéØ En iyi loss g√ºncellendi: 4.1814\n",
            "üìà Loss d√ºzenli d√º≈ü√ºyor, devam et!\n",
            "\n",
            "üöÄ EPOCH 5/20\n",
            "  Batch 0, Loss: 4.0896\n",
            "  Batch 2000, Loss: 5.3022\n",
            "  Batch 4000, Loss: 4.1901\n",
            "  Batch 6000, Loss: 2.7861\n",
            "  Batch 8000, Loss: 3.3338\n",
            "  Batch 10000, Loss: 5.9448\n",
            "  Batch 12000, Loss: 2.7984\n",
            "  Batch 14000, Loss: 3.6370\n",
            "  Batch 16000, Loss: 3.0689\n",
            "  Batch 18000, Loss: 3.2131\n",
            "  Batch 20000, Loss: 3.0720\n",
            "  Batch 22000, Loss: 5.2116\n",
            "  Batch 24000, Loss: 3.0189\n",
            "  Batch 26000, Loss: 3.1894\n",
            "‚úÖ Epoch 5 - Avg Loss: 4.1132 (1023.7s)\n",
            "üéØ En iyi loss g√ºncellendi: 4.1132\n",
            "üìà Loss d√ºzenli d√º≈ü√ºyor, devam et!\n",
            "\n",
            "üöÄ EPOCH 6/20\n",
            "  Batch 0, Loss: 4.2460\n",
            "  Batch 2000, Loss: 5.3286\n",
            "  Batch 4000, Loss: 3.9520\n",
            "  Batch 6000, Loss: 2.8117\n",
            "  Batch 8000, Loss: 3.3291\n",
            "  Batch 10000, Loss: 5.6080\n",
            "  Batch 12000, Loss: 2.8155\n",
            "  Batch 14000, Loss: 3.5976\n",
            "  Batch 16000, Loss: 3.0600\n",
            "  Batch 18000, Loss: 3.1469\n",
            "  Batch 20000, Loss: 3.0917\n",
            "  Batch 22000, Loss: 5.3014\n",
            "  Batch 24000, Loss: 2.8989\n",
            "  Batch 26000, Loss: 3.0554\n",
            "‚úÖ Epoch 6 - Avg Loss: 4.0746 (1030.9s)\n",
            "üéØ En iyi loss g√ºncellendi: 4.0746\n",
            "üìà Loss d√ºzenli d√º≈ü√ºyor, devam et!\n",
            "\n",
            "üöÄ EPOCH 7/20\n",
            "  Batch 0, Loss: 4.1646\n",
            "  Batch 2000, Loss: 5.3101\n",
            "  Batch 4000, Loss: 3.9275\n",
            "  Batch 6000, Loss: 2.7683\n",
            "  Batch 8000, Loss: 3.3659\n",
            "  Batch 10000, Loss: 5.7183\n",
            "  Batch 12000, Loss: 2.7631\n",
            "  Batch 14000, Loss: 3.5708\n",
            "  Batch 16000, Loss: 2.9632\n",
            "  Batch 18000, Loss: 3.0795\n",
            "  Batch 20000, Loss: 2.9358\n",
            "  Batch 22000, Loss: 5.2142\n",
            "  Batch 24000, Loss: 2.9867\n",
            "  Batch 26000, Loss: 3.1286\n",
            "‚úÖ Epoch 7 - Avg Loss: 4.0449 (1029.2s)\n",
            "üéØ En iyi loss g√ºncellendi: 4.0449\n",
            "üìà Loss d√ºzenli d√º≈ü√ºyor, devam et!\n",
            "\n",
            "üöÄ EPOCH 8/20\n",
            "  Batch 0, Loss: 4.2336\n",
            "  Batch 2000, Loss: 5.2639\n",
            "  Batch 4000, Loss: 3.9595\n",
            "  Batch 6000, Loss: 2.8247\n",
            "  Batch 8000, Loss: 3.4484\n",
            "  Batch 10000, Loss: 5.4982\n",
            "  Batch 12000, Loss: 2.7332\n",
            "  Batch 14000, Loss: 3.7588\n",
            "  Batch 16000, Loss: 2.9321\n",
            "  Batch 18000, Loss: 2.9818\n",
            "  Batch 20000, Loss: 2.9458\n",
            "  Batch 22000, Loss: 5.1990\n",
            "  Batch 24000, Loss: 2.9985\n",
            "  Batch 26000, Loss: 3.0108\n",
            "‚úÖ Epoch 8 - Avg Loss: 4.0188 (1022.6s)\n",
            "üéØ En iyi loss g√ºncellendi: 4.0188\n",
            "üìà Loss d√ºzenli d√º≈ü√ºyor, devam et!\n",
            "\n",
            "üöÄ EPOCH 9/20\n",
            "  Batch 0, Loss: 4.3796\n",
            "  Batch 2000, Loss: 5.2667\n",
            "  Batch 4000, Loss: 3.8920\n",
            "  Batch 6000, Loss: 2.8003\n",
            "  Batch 8000, Loss: 3.3357\n",
            "  Batch 10000, Loss: 5.4759\n",
            "  Batch 12000, Loss: 2.7947\n",
            "  Batch 14000, Loss: 3.6173\n",
            "  Batch 16000, Loss: 2.9521\n",
            "  Batch 18000, Loss: 3.0611\n",
            "  Batch 20000, Loss: 3.0357\n",
            "  Batch 22000, Loss: 5.1188\n",
            "  Batch 24000, Loss: 2.9445\n",
            "  Batch 26000, Loss: 3.0820\n",
            "‚úÖ Epoch 9 - Avg Loss: 3.9972 (1026.3s)\n",
            "üéØ En iyi loss g√ºncellendi: 3.9972\n",
            "üìà Loss d√ºzenli d√º≈ü√ºyor, devam et!\n",
            "\n",
            "üöÄ EPOCH 10/20\n",
            "  Batch 0, Loss: 4.3830\n",
            "  Batch 2000, Loss: 5.1969\n",
            "  Batch 4000, Loss: 3.8910\n",
            "  Batch 6000, Loss: 2.8254\n",
            "  Batch 8000, Loss: 3.3422\n",
            "  Batch 10000, Loss: 5.3474\n",
            "  Batch 12000, Loss: 2.8653\n",
            "  Batch 14000, Loss: 3.5730\n",
            "  Batch 16000, Loss: 2.9050\n",
            "  Batch 18000, Loss: 3.0590\n",
            "  Batch 20000, Loss: 3.0467\n",
            "  Batch 22000, Loss: 5.0702\n",
            "  Batch 24000, Loss: 2.9379\n",
            "  Batch 26000, Loss: 3.0204\n",
            "‚úÖ Epoch 10 - Avg Loss: 3.9809 (1028.5s)\n",
            "üéØ En iyi loss g√ºncellendi: 3.9809\n",
            "üìà Loss d√ºzenli d√º≈ü√ºyor, devam et!\n",
            "\n",
            "üöÄ EPOCH 11/20\n",
            "  Batch 0, Loss: 4.3804\n",
            "  Batch 2000, Loss: 5.1665\n",
            "  Batch 4000, Loss: 3.8059\n",
            "  Batch 6000, Loss: 2.8155\n",
            "  Batch 8000, Loss: 3.3161\n",
            "  Batch 10000, Loss: 5.4536\n",
            "  Batch 12000, Loss: 2.8361\n",
            "  Batch 14000, Loss: 3.5553\n",
            "  Batch 16000, Loss: 2.8438\n",
            "  Batch 18000, Loss: 3.1013\n",
            "  Batch 20000, Loss: 2.9038\n",
            "  Batch 22000, Loss: 5.0583\n",
            "  Batch 24000, Loss: 2.9565\n",
            "  Batch 26000, Loss: 3.1000\n",
            "‚úÖ Epoch 11 - Avg Loss: 3.9693 (1034.3s)\n",
            "üéØ En iyi loss g√ºncellendi: 3.9693\n",
            "üìà Loss d√ºzenli d√º≈ü√ºyor, devam et!\n",
            "\n",
            "üöÄ EPOCH 12/20\n",
            "  Batch 0, Loss: 4.2392\n",
            "  Batch 2000, Loss: 5.1578\n",
            "  Batch 4000, Loss: 3.7628\n",
            "  Batch 6000, Loss: 2.7815\n",
            "  Batch 8000, Loss: 3.2909\n",
            "  Batch 10000, Loss: 5.5628\n",
            "  Batch 12000, Loss: 2.8006\n",
            "  Batch 14000, Loss: 3.5747\n",
            "  Batch 16000, Loss: 3.0052\n",
            "  Batch 18000, Loss: 3.0382\n",
            "  Batch 20000, Loss: 2.9690\n",
            "  Batch 22000, Loss: 5.0599\n",
            "  Batch 24000, Loss: 2.9004\n",
            "  Batch 26000, Loss: 3.0338\n",
            "‚úÖ Epoch 12 - Avg Loss: 3.9613 (1036.5s)\n",
            "üéØ En iyi loss g√ºncellendi: 3.9613\n",
            "üìà Loss d√ºzenli d√º≈ü√ºyor, devam et!\n",
            "\n",
            "üöÄ EPOCH 13/20\n",
            "  Batch 0, Loss: 4.2340\n",
            "  Batch 2000, Loss: 5.2209\n",
            "  Batch 4000, Loss: 3.6586\n",
            "  Batch 6000, Loss: 2.8134\n",
            "  Batch 8000, Loss: 3.2708\n",
            "  Batch 10000, Loss: 5.5147\n",
            "  Batch 12000, Loss: 2.6317\n",
            "  Batch 14000, Loss: 3.4699\n",
            "  Batch 16000, Loss: 3.0819\n",
            "  Batch 18000, Loss: 3.0194\n",
            "  Batch 20000, Loss: 2.9689\n",
            "  Batch 22000, Loss: 5.0671\n",
            "  Batch 24000, Loss: 2.9254\n",
            "  Batch 26000, Loss: 3.1634\n",
            "‚úÖ Epoch 13 - Avg Loss: 3.9555 (1028.6s)\n",
            "üéØ En iyi loss g√ºncellendi: 3.9555\n",
            "üìà Loss d√ºzenli d√º≈ü√ºyor, devam et!\n",
            "\n",
            "üöÄ EPOCH 14/20\n",
            "  Batch 0, Loss: 4.2580\n",
            "  Batch 2000, Loss: 5.2251\n",
            "  Batch 4000, Loss: 3.7305\n",
            "  Batch 6000, Loss: 2.6903\n",
            "  Batch 8000, Loss: 3.2645\n",
            "  Batch 10000, Loss: 5.6113\n",
            "  Batch 12000, Loss: 2.7315\n",
            "  Batch 14000, Loss: 3.5181\n",
            "  Batch 16000, Loss: 2.9802\n",
            "  Batch 18000, Loss: 3.1372\n",
            "  Batch 20000, Loss: 2.9443\n",
            "  Batch 22000, Loss: 5.0531\n",
            "  Batch 24000, Loss: 2.9034\n",
            "  Batch 26000, Loss: 2.9358\n",
            "‚úÖ Epoch 14 - Avg Loss: 3.9523 (1048.0s)\n",
            "üéØ En iyi loss g√ºncellendi: 3.9523\n",
            "üìà Loss d√ºzenli d√º≈ü√ºyor, devam et!\n",
            "\n",
            "üöÄ EPOCH 15/20\n",
            "  Batch 0, Loss: 4.3662\n",
            "  Batch 2000, Loss: 5.2281\n",
            "  Batch 4000, Loss: 3.7869\n",
            "  Batch 6000, Loss: 2.6173\n",
            "  Batch 8000, Loss: 3.2452\n",
            "  Batch 10000, Loss: 5.6014\n",
            "  Batch 12000, Loss: 2.6524\n",
            "  Batch 14000, Loss: 3.4807\n",
            "  Batch 16000, Loss: 2.9642\n",
            "  Batch 18000, Loss: 3.0811\n",
            "  Batch 20000, Loss: 2.8922\n",
            "  Batch 22000, Loss: 5.0931\n",
            "  Batch 24000, Loss: 2.9115\n",
            "  Batch 26000, Loss: 3.0185\n",
            "‚úÖ Epoch 15 - Avg Loss: 3.9476 (1030.9s)\n",
            "üéØ En iyi loss g√ºncellendi: 3.9476\n",
            "üìà Loss d√ºzenli d√º≈ü√ºyor, devam et!\n",
            "\n",
            "üöÄ EPOCH 16/20\n",
            "  Batch 0, Loss: 4.2789\n",
            "  Batch 2000, Loss: 5.3185\n",
            "  Batch 4000, Loss: 3.9110\n",
            "  Batch 6000, Loss: 2.6041\n",
            "  Batch 8000, Loss: 3.2707\n",
            "  Batch 10000, Loss: 5.7145\n",
            "  Batch 12000, Loss: 2.6841\n",
            "  Batch 14000, Loss: 3.4985\n",
            "  Batch 16000, Loss: 3.0767\n",
            "  Batch 18000, Loss: 3.0626\n",
            "  Batch 20000, Loss: 2.9013\n",
            "  Batch 22000, Loss: 5.0014\n",
            "  Batch 24000, Loss: 2.9864\n",
            "  Batch 26000, Loss: 2.8811\n",
            "‚úÖ Epoch 16 - Avg Loss: 3.9441 (1043.0s)\n",
            "üéØ En iyi loss g√ºncellendi: 3.9441\n",
            "üìà Loss d√ºzenli d√º≈ü√ºyor, devam et!\n",
            "\n",
            "üöÄ EPOCH 17/20\n",
            "  Batch 0, Loss: 4.3029\n",
            "  Batch 2000, Loss: 5.3088\n",
            "  Batch 4000, Loss: 3.8143\n",
            "  Batch 6000, Loss: 2.5725\n",
            "  Batch 8000, Loss: 3.2873\n",
            "  Batch 10000, Loss: 5.7554\n",
            "  Batch 12000, Loss: 2.7037\n",
            "  Batch 14000, Loss: 3.5072\n",
            "  Batch 16000, Loss: 3.0959\n",
            "  Batch 18000, Loss: 3.0186\n",
            "  Batch 20000, Loss: 2.8938\n",
            "  Batch 22000, Loss: 5.0512\n",
            "  Batch 24000, Loss: 2.9230\n",
            "  Batch 26000, Loss: 2.8807\n",
            "‚úÖ Epoch 17 - Avg Loss: 3.9391 (1035.1s)\n",
            "üéØ En iyi loss g√ºncellendi: 3.9391\n",
            "üìà Loss d√ºzenli d√º≈ü√ºyor, devam et!\n",
            "\n",
            "üöÄ EPOCH 18/20\n",
            "  Batch 0, Loss: 4.2438\n",
            "  Batch 2000, Loss: 5.3047\n",
            "  Batch 4000, Loss: 3.7467\n",
            "  Batch 6000, Loss: 2.6304\n",
            "  Batch 8000, Loss: 3.3684\n",
            "  Batch 10000, Loss: 5.6849\n",
            "  Batch 12000, Loss: 2.7028\n",
            "  Batch 14000, Loss: 3.6009\n",
            "  Batch 16000, Loss: 2.8827\n",
            "  Batch 18000, Loss: 3.0803\n",
            "  Batch 20000, Loss: 2.9115\n",
            "  Batch 22000, Loss: 5.0303\n",
            "  Batch 24000, Loss: 2.9613\n",
            "  Batch 26000, Loss: 3.1424\n",
            "‚úÖ Epoch 18 - Avg Loss: 3.9333 (1037.7s)\n",
            "üéØ En iyi loss g√ºncellendi: 3.9333\n",
            "üìà Loss d√ºzenli d√º≈ü√ºyor, devam et!\n",
            "\n",
            "üöÄ EPOCH 19/20\n",
            "  Batch 0, Loss: 4.2955\n",
            "  Batch 2000, Loss: 5.2341\n",
            "  Batch 4000, Loss: 3.8880\n",
            "  Batch 6000, Loss: 2.6761\n",
            "  Batch 8000, Loss: 3.2696\n",
            "  Batch 10000, Loss: 5.7860\n",
            "  Batch 12000, Loss: 2.6549\n",
            "  Batch 14000, Loss: 3.5728\n",
            "  Batch 16000, Loss: 3.0541\n",
            "  Batch 18000, Loss: 3.0720\n",
            "  Batch 20000, Loss: 2.9615\n",
            "  Batch 22000, Loss: 5.0980\n",
            "  Batch 24000, Loss: 2.9566\n",
            "  Batch 26000, Loss: 3.0689\n",
            "‚úÖ Epoch 19 - Avg Loss: 3.9302 (1021.9s)\n",
            "üéØ En iyi loss g√ºncellendi: 3.9302\n",
            "üìà Loss d√ºzenli d√º≈ü√ºyor, devam et!\n",
            "\n",
            "üöÄ EPOCH 20/20\n",
            "  Batch 0, Loss: 4.2547\n",
            "  Batch 2000, Loss: 5.1401\n",
            "  Batch 4000, Loss: 3.6770\n",
            "  Batch 6000, Loss: 2.6506\n",
            "  Batch 8000, Loss: 3.3232\n",
            "  Batch 10000, Loss: 5.7833\n",
            "  Batch 12000, Loss: 2.6488\n",
            "  Batch 14000, Loss: 3.5727\n",
            "  Batch 16000, Loss: 2.9112\n",
            "  Batch 18000, Loss: 3.1753\n",
            "  Batch 20000, Loss: 3.0518\n",
            "  Batch 22000, Loss: 5.0727\n",
            "  Batch 24000, Loss: 2.9598\n",
            "  Batch 26000, Loss: 2.9225\n",
            "‚úÖ Epoch 20 - Avg Loss: 3.9262 (1027.4s)\n",
            "üéØ En iyi loss g√ºncellendi: 3.9262\n",
            "üìà Loss d√ºzenli d√º≈ü√ºyor, devam et!\n",
            "\n",
            "üèÅ Eƒüitim bitti! En iyi loss: 3.9262\n",
            "üìä Loss ge√ßmi≈üi: [4.993515100221572, 4.437014542327901, 4.27599477702649, 4.181446173935618, 4.113174221034103, 4.074563126520496, 4.044911695061731, 4.018799711965072, 3.9971897507629817, 3.9809062827807864, 3.9693071491775425, 3.9613391918662657, 3.955505344268259, 3.9522669539836115, 3.9475902295058196, 3.9440951686161196, 3.9391050769558147, 3.933309389135601, 3.930163905973351, 3.926242006722853]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üí° √ñneri: Loss h√¢l√¢ y√ºksek. epochs = 50-100 ile tekrar dene.\n"
          ]
        }
      ],
      "source": [
        "# 1. Loss takibi i√ßin liste\n",
        "loss_history = []\n",
        "\n",
        "# 2. Early stopping i√ßin deƒüi≈ükenler\n",
        "best_loss = float('inf')\n",
        "patience = 10  # 10 epoch loss d√º≈ümezse dur (artƒ±rƒ±ldƒ±)\n",
        "patience_counter = 0\n",
        "\n",
        "# 3. Epochs - artƒ±rƒ±ldƒ±\n",
        "epochs = 20  # 20 epoch ile ba≈üla\n",
        "\n",
        "# 4. Learning rate scheduler ekle\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.5, patience=5\n",
        ")\n",
        "\n",
        "print(f\"Dataset boyutu: {len(dataset)}\")\n",
        "print(f\"Ba≈ülangƒ±√ß epochs: {epochs}\")\n",
        "print(f\"Early stopping: {patience} epoch patience\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nüöÄ EPOCH {epoch + 1}/{epochs}\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    total_loss = 0.\n",
        "\n",
        "    # Eƒüitim d√∂ng√ºs√º\n",
        "    for batch_idx, (input, target) in enumerate(dataset):\n",
        "        input = input.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = u_model(input)\n",
        "        loss = loss_fn(pred, target)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Daha az frequent print (2000'de bir)\n",
        "        if batch_idx % 2000 == 0:\n",
        "            print(f\"  Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    average_loss = total_loss / len(dataset)\n",
        "    loss_history.append(average_loss)\n",
        "\n",
        "    print(f\"‚úÖ Epoch {epoch + 1} - Avg Loss: {average_loss:.4f} ({epoch_time:.1f}s)\")\n",
        "\n",
        "    # Learning rate scheduler step\n",
        "    old_lr = optimizer.param_groups[0]['lr']\n",
        "    scheduler.step(average_loss)\n",
        "    new_lr = optimizer.param_groups[0]['lr']\n",
        "    if old_lr != new_lr:\n",
        "        print(f\"üîΩ Learning rate reduced: {old_lr:.6f} ‚Üí {new_lr:.6f}\")\n",
        "\n",
        "    if average_loss < best_loss:\n",
        "        best_loss = average_loss\n",
        "        patience_counter = 0\n",
        "        print(f\"üéØ En iyi loss g√ºncellendi: {best_loss:.4f}\")\n",
        "\n",
        "        # Model kaydet\n",
        "        torch.save(u_model.state_dict(), 'best_model.pth')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"‚ö†Ô∏è  Loss d√º≈ümedi, patience: {patience_counter}/{patience}\")\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"üõë Early stopping! {patience} epoch boyunca iyile≈üme yok.\")\n",
        "            break\n",
        "\n",
        "    # Loss trend analizi\n",
        "    if len(loss_history) >= 3:\n",
        "        recent_trend = loss_history[-3:]\n",
        "        if all(recent_trend[i] <= recent_trend[i-1] for i in range(1, len(recent_trend))):\n",
        "            print(\"üìà Loss d√ºzenli d√º≈ü√ºyor, devam et!\")\n",
        "        else:\n",
        "            print(\"üìä Loss dalgalƒ±, learning rate scheduler devrede\")\n",
        "\n",
        "    # ƒ∞lerleme durumu\n",
        "    if average_loss < 2.0:\n",
        "        print(\"üåü Loss 2.0'ƒ±n altƒ±nda! ƒ∞yi gidiyor.\")\n",
        "    elif average_loss < 1.0:\n",
        "        print(\"üéâ Loss 1.0'ƒ±n altƒ±nda! M√ºkemmel!\")\n",
        "\n",
        "print(f\"\\nüèÅ Eƒüitim bitti! En iyi loss: {best_loss:.4f}\")\n",
        "print(f\"üìä Loss ge√ßmi≈üi: {loss_history}\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(loss_history, 'b-', linewidth=2, marker='o')\n",
        "plt.title('Training Loss Over Epochs', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Eƒüer loss h√¢l√¢ y√ºksekse (>2.0), daha fazla epoch √∂ner\n",
        "if best_loss > 2.0:\n",
        "    print(\"\\nüí° √ñneri: Loss h√¢l√¢ y√ºksek. epochs = 50-100 ile tekrar dene.\")\n",
        "elif best_loss > 1.0:\n",
        "    print(\"\\nüí° √ñneri: ƒ∞yi gidiyor! epochs = 30-50 ile devam edebilirsin.\")\n",
        "else:\n",
        "    print(\"\\nüéä Harika! Model iyi √∂ƒürenmi≈ü g√∂r√ºn√ºyor.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "WBksGzOffz3f",
        "outputId": "c3451832-811b-483f-d6f8-68b724cba7db"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3831427252.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"u_model.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mu_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"u_model.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "torch.save(u_model.state_dict(), \"u_model.pth\")\n",
        "u_model.load_state_dict(torch.load(\"u_model.pth\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLDpycw2p3r6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
